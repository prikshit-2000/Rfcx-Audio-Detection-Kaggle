{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import scipy\nimport numpy as np\nimport pandas as pd\nimport librosa as lb\nimport librosa.display as lbd\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras as k\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Activation, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import label_ranking_average_precision_score as lrap\nfrom PIL import Image\nimport seaborn as sns\nimport warnings\nimport glob\nimport json\nimport os\nimport re\n\npd.set_option('display.max_columns', 20)\nnp.set_printoptions(suppress=True)\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_samples = glob.glob('../input/rfcx-species-audio-detection/train/*')\ntest_samples = glob.glob('../input/rfcx-species-audio-detection/test/*')\nprint(\"Number of train samples : \", len(train_samples), \"\\nNumber of test  samples : \", len(test_samples))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tp = pd.read_csv('../input/rfcx-species-audio-detection/train_tp.csv')\ndata_fp = pd.read_csv('../input/rfcx-species-audio-detection/train_fp.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data_tp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data_fp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA PRE-PROCESSING**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"shuffled_data = shuffle(data_tp)\nshuffled_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = shuffled_data[:int(0.9*len(shuffled_data))]\nval_data = shuffled_data[int(0.9*len(shuffled_data)):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 24\nsampling_rate = 44100\nwindow_size = 10\nbase_path = '../input/rfcx-species-audio-detection/train/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./train')\nos.mkdir('./val')\nfor cls in range(num_classes):\n    os.mkdir('./train/class_' + str(cls))\n    os.mkdir('./val/class_' + str(cls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_spectrogram(rec_id, species_id, start, end, base_file, count):\n    plt.interactive(False)\n    sound_clip, sample_rate = lb.load(base_path + rec_id + '.flac', sr=sampling_rate)\n    trimmed_sound_clip = sound_clip[int(start*sample_rate):int(end*sample_rate)]\n    fig = plt.figure(figsize=(3.56, 3.56))\n    ax = fig.add_subplot(111)\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_frame_on(False)\n    S = lb.feature.melspectrogram(y=trimmed_sound_clip, sr=sample_rate)\n    lbd.specshow(lb.power_to_db(S, ref=np.max))\n    filename  = base_file + 'class_' + str(species_id) + '/img_' + str(count) + '.jpg'\n    plt.savefig(filename)\n    plt.close()    \n    fig.clf()\n    plt.close(fig)\n    plt.close('all')\n    del sound_clip, trimmed_sound_clip, sample_rate, fig, ax, S","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_train_and_val_data(data, base_file):\n    count = 1\n    for i in range(len(data)):\n        d = data.iloc[i]\n        center = (d.t_min +  d.t_max) / 2\n        start = center - (window_size//2)\n        end = center + (window_size//2)\n        if start < 0:\n            start = 0\n            end = start + window_size\n        if end > 60:\n            end = 60\n            start = end - window_size\n        rec_id = d.recording_id\n        species_id = d.species_id\n        create_spectrogram(rec_id, species_id, start, end, base_file, count)\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Uncomment this to create the data for mislabelled data\n\n#create_train_and_val_data(train_data, './train/')\n#create_train_and_val_data(val_data, './val/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model for labelling unlabelled data"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (256, 256, 3)\nbatch_size = 1\nnum_classes = 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = datagen.flow_from_directory('../input/data-for-mislabelled-data/data_preprocessing/train/', target_size=input_shape[0:2], batch_size=batch_size, class_mode='categorical', shuffle=True)\nval = datagen.flow_from_directory('../input/data-for-mislabelled-data/data_preprocessing/val/', target_size=input_shape[0:2], batch_size=batch_size, class_mode='categorical', shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(input_shape=input_shape, filters=8, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(7, 7), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=32, kernel_size=(9, 9), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=64, kernel_size=(9, 9), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.6))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1098, activation='relu'))\nmodel.add(Dropout(0.78))\n\nmodel.add(Dense(1098, activation='relu'))\nmodel.add(Dropout(0.78))\n\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt, loss=CategoricalCrossentropy(), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train, steps_per_epoch=len(train), epochs=100, verbose=1, validation_data=val, validation_steps=len(val), workers=4, use_multiprocessing=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nplt.subplot(121)\nplt.plot([i for i in range(len(history.history['loss']))], history.history['loss'], label='train')\nplt.plot([i for i in range(len(history.history['val_loss']))], history.history['val_loss'], label='val')\nplt.title('Train vs Val Loss')\nplt.legend()\nplt.subplot(122)\nplt.plot([i for i in range(len(history.history['accuracy']))], history.history['accuracy'], label='train')\nplt.plot([i for i in range(len(history.history['val_accuracy']))], history.history['val_accuracy'], label='val')\nplt.title('Train vs Val Accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model_for_data.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Final data and labels creation**"},{"metadata":{"trusted":true},"cell_type":"code","source":" model = load_model('../input/model-for-unlabelled-data/model_for_data.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = sorted([re.findall(r'class_\\d+', clas)[0] for clas in glob.glob('../input/data-for-mislabelled-data/data_preprocessing/train/*')])\nlabel_dict = {i:int(re.findall(r'class_(\\d+)', clas)[0]) for i, clas in zip(range(0, len(classes)), classes)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spectogram(audio, sample_rate):\n    plt.interactive(False)\n    fig = plt.figure(figsize=(3.56, 3.56))\n    ax = fig.add_subplot(111)\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    ax.set_frame_on(False)\n    S = lb.feature.melspectrogram(y=audio, sr=sample_rate)\n    lbd.specshow(lb.power_to_db(S, ref=np.max))\n    plt.close()\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_species_if_labelled(name, df):\n    return list(df[df['recording_id'] == name].species_id.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_label(audio, sample_rate, label_dict, model, name, df):\n    label = [0] * 24\n    species = return_species_if_labelled(name, df)\n    for i in species:\n        label[i] = 1\n    audio_windows = []\n    for i in range(0, 60, 10):\n        audio_windows.append(audio[i*sample_rate:(i+10)*sample_rate])\n    for trimmed_audio in audio_windows:\n        fig = spectogram(trimmed_audio, sample_rate)\n        fig.canvas.draw()\n        trimmed_spec = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n        trimmed_spec = trimmed_spec.reshape((1, ) + fig.canvas.get_width_height()[::-1] + (3,))\n        label[label_dict[np.argmax(model.predict(trimmed_spec))]] = 1\n        fig.clf()\n        plt.close(fig)\n        plt.close('all')\n        del fig\n    return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_train_data_and_label(record, name, frmt, label_dict, sampling_rate, model, df):\n    audio, sample_rate = lb.load(record, sr=sampling_rate)\n    label = create_label(audio, sample_rate, label_dict, model, name, df)\n    fig = spectogram(audio, sample_rate)\n    filename  = './train/' + name + '.' + frmt\n    fig.savefig(filename)\n    plt.close()\n    fig.clf()\n    plt.close(fig)\n    plt.close('all')\n    del fig\n    return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels =  {}\nindex = 1\nfor record in glob.glob('../input/rfcx-species-audio-detection/train/*'):\n    name = re.findall(r'/train/(.+).flac', record)[0]\n    l = create_train_data_and_label(record, name, 'jpg', label_dict, sampling_rate, model, data_tp)\n    labels[name] = l\n    print(str(index) + ' record completed!')\n    index += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('labels.json', 'w') as f:\n    json.dump(labels, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -cvzf train_data.tar.gz ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.FileLink('./train_data.tar.g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Final Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = glob.glob('../input/training-data/train/*')\ntrain = shuffle(train)\nwith open('../input/training-data/labels.json', 'r') as f:\n    labels = json.load(f)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.zeros((len(train), 256, 256, 3))\nY = np.zeros((len(train), 24))","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_name(path):\n    return re.findall(r'train/(.+)\\.jpg', path)[0]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for exp in range(len(train)):\n    X[exp] = (np.array(Image.open(train[exp]))/255)\n    Y[exp] = np.array(labels[extract_name(train[exp])])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X : ', X.shape)\nprint('Shape of Y : ', Y.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"Shape of X :  (4727, 256, 256, 3)\nShape of Y :  (4727, 24)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = X[:int(0.90*len(train))], X[int(0.90*len(train)):], Y[:int(0.90*len(train))], Y[int(0.90*len(train)):]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X, Y","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train : ', X_train.shape)\nprint('Shape of y_train : ', y_train.shape)\nprint('Shape of X_val : ', X_val.shape)\nprint('Shape of y_val : ', y_val.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"Shape of X_train :  (4254, 256, 256, 3)\nShape of y_train :  (4254, 24)\nShape of X_val :  (473, 256, 256, 3)\nShape of y_val :  (473, 24)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(input_shape=X_train.shape[1:], filters=8, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(7, 7), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters=32, kernel_size=(9, 9), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1098, activation='relu'))\nmodel.add(Dropout(0.78))\n\nmodel.add(Dense(1098, activation='relu'))\nmodel.add(Dropout(0.78))\n\nmodel.add(Dense(24, activation='sigmoid'))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(lr=0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 20","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lraps = []\nfor epoch in range(epochs):\n    l = []\n    for batch in range(0, ((X_train.shape[0] - (X_train.shape[0] % batch_size)) + 1) - batch_size, batch_size):\n        x_t = X_train[batch:batch+batch_size]\n        y_t = y_train[batch:batch+batch_size]\n        history = model.fit(x_t, y_t, epochs=1, steps_per_epoch=1, verbose=0, workers=4, use_multiprocessing=True)\n        l.append(lrap(y_t, model.predict(x_t)))\n        del x_t, y_t\n    if X_train.shape[0] % batch_size != 0:\n        history = model.fit(X_train[batch:], y_train[batch:], epochs=1, steps_per_epoch=1, verbose=0, workers=4, use_multiprocessing=True)\n        l.append(lrap(y_train[batch:], model.predict(X_train[batch:])))\n    avg_lrap = sum(l)/len(l)\n    lraps.append(avg_lrap)\n    print('Epoch', (epoch+1),':\\nTraining accuracy (LRAP): ', avg_lrap)","execution_count":22,"outputs":[{"output_type":"stream","text":"Training accuracy :  0.9482475630471786\nTraining accuracy :  0.9519299064481883\nTraining accuracy :  0.9509968985664559\nTraining accuracy :  0.9553735746184059\nTraining accuracy :  0.9583465821287896\nTraining accuracy :  0.9624669338847007\nTraining accuracy :  0.9636812487865929\nTraining accuracy :  0.9672239209855997\nTraining accuracy :  0.9686337009382788\nTraining accuracy :  0.9682411562642468\nTraining accuracy :  0.9703845761373022\nTraining accuracy :  0.9717381901215159\nTraining accuracy :  0.9735570178283703\nTraining accuracy :  0.9744232043582471\nTraining accuracy :  0.973977260103162\nTraining accuracy :  0.9769787712027953\nTraining accuracy :  0.9773779778623983\nTraining accuracy :  0.9788506524804993\nTraining accuracy :  0.9801706991624493\nTraining accuracy :  0.9806836479306009\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print('Validation Accuracy (LRAP): ', lrap(y_val, model.predict(X_val))","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"0.8190176079035058"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = glob.glob('../input/test-data/test/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv('../input/rfcx-species-audio-detection/sample_submission.csv')","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=submission_example.columns, index=[i for i in range(len(train))])","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_name(path):\n    return re.findall(r'test/(.+)\\.jpg', path)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for exp in range(len(test)):\n    submission.iloc[exp, :] = [extract_name(test[exp])] + (list(model.predict((np.array(Image.open(test[exp]))/255).reshape((1, 256, 256, 3)))).squeeze())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.set_index('recording_id', inplace=True)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}